{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequential NLP Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLmkfrtjXTfg"
      },
      "source": [
        "# Digital content and entertainment industry\n",
        "\n",
        "The objective is to build a text classification model that\n",
        "analyses the customer's sentiments based on their reviews in the IMDB database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhxalEKPOb0i"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3XdVxYjXV32"
      },
      "source": [
        "## Loading and analysing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OVbycblOiKz",
        "outputId": "9c9ff1c7-a073-4317-b94c-5b91c8f47008"
      },
      "source": [
        "(train_data, train_label), (test_data, test_label) = tf.keras.datasets.imdb.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siNFCElyYA_F"
      },
      "source": [
        "### Printing first 5 reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gKk9xuvXzos",
        "outputId": "2ef287d7-8f8e-42c7-d470-64394df53502"
      },
      "source": [
        "for i in range(5):\n",
        "    print('Review:', train_data[i])\n",
        "    print('Label:', train_label[i])\n",
        "    print('_' * 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "Label: 1\n",
            "__________\n",
            "Review: [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
            "Label: 0\n",
            "__________\n",
            "Review: [1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n",
            "Label: 0\n",
            "__________\n",
            "Review: [1, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 2, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 2, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 2, 192, 5, 1219, 3890, 19, 2, 217, 4122, 1710, 537, 2, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 2, 594, 7, 5168, 94, 9096, 3987, 2, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 2, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 2, 19, 49, 7, 4, 1885, 2, 1118, 25, 80, 126, 842, 10, 10, 2, 2, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 2, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 2, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 2, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 2, 1311, 8, 4, 2, 7, 31, 7, 2, 91, 2, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 2, 1775, 3353, 2, 1846, 4, 2, 7, 154, 5, 4, 518, 53, 2, 2, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 2, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 2, 9, 242, 4, 91, 1202, 2, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 2, 13, 188, 1076, 3222, 19, 4, 2, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 2, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 2, 7, 5991, 5, 94, 40, 25, 238, 60, 2, 4, 2, 804, 2, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 2, 23, 12, 1685, 195, 25, 238, 60, 796, 2, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574]\n",
            "Label: 1\n",
            "__________\n",
            "Review: [1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 2, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113]\n",
            "Label: 0\n",
            "__________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIviufxPYOqK"
      },
      "source": [
        "We see that the text of the review has been encoded as a sequence of integers. Each word in the text is represented as an integer. A dictionary called the **vocabulary** links each word to a unique integer.\n",
        "\n",
        "To decode the review, we need to make use of the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-mo3IhJOsm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb81663-5a64-4404-9edf-2071c5361e06"
      },
      "source": [
        "review_words = tf.keras.datasets.imdb.get_word_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWyKHqiEO5bV"
      },
      "source": [
        "vocabulary = {k: (v + 3) for k, v in review_words.items()} \n",
        "\n",
        "vocabulary[\"<PAD>\"] = 0\n",
        "vocabulary[\"<START>\"] = 1\n",
        "vocabulary[\"<UNKNOWN>\"] = 2\n",
        "vocabulary[\"<UNUSED>\"] = 3\n",
        "\n",
        "index = dict([(value, key) for (key, value) in vocabulary.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([index.get(i, '?') for i in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFToNLOfYsEo"
      },
      "source": [
        "### Printing first 5 reviews with decoded text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJkfOTsIWF1O",
        "outputId": "be6ba23a-a25d-4511-9188-c420c45f76be"
      },
      "source": [
        "for i in range(5):\n",
        "    print('Review:', decode_review(train_data[i]))\n",
        "    print('Label:', train_label[i])\n",
        "    print('_' * 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: <START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNKNOWN> is an amazing actor and now the same being director <UNKNOWN> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNKNOWN> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNKNOWN> to the two little boy's that played the <UNKNOWN> of norman and paul they were just brilliant children are often left out of the <UNKNOWN> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "Label: 1\n",
            "__________\n",
            "Review: <START> big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal <UNKNOWN> the hair is big lots of boobs <UNKNOWN> men wear those cut <UNKNOWN> shirts that show off their <UNKNOWN> sickening that men actually wore them and the music is just <UNKNOWN> trash that plays over and over again in almost every scene there is trashy music boobs and <UNKNOWN> taking away bodies and the gym still doesn't close for <UNKNOWN> all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
            "Label: 0\n",
            "__________\n",
            "Review: <START> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <UNKNOWN> working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <UNKNOWN> this is to watch save yourself an hour a bit of your life\n",
            "Label: 0\n",
            "__________\n",
            "Review: <START> the <UNKNOWN> <UNKNOWN> at storytelling the traditional sort many years after the event i can still see in my <UNKNOWN> eye an elderly lady my friend's mother retelling the battle of <UNKNOWN> she makes the characters come alive her passion is that of an eye witness one to the events on the <UNKNOWN> heath a mile or so from where she lives br br of course it happened many years before she was born but you wouldn't guess from the way she tells it the same story is told in bars the length and <UNKNOWN> of scotland as i discussed it with a friend one night in <UNKNOWN> a local cut in to give his version the discussion continued to closing time br br stories passed down like this become part of our being who doesn't remember the stories our parents told us when we were children they become our invisible world and as we grow older they maybe still serve as inspiration or as an emotional <UNKNOWN> fact and fiction blend with <UNKNOWN> role models warning stories <UNKNOWN> magic and mystery br br my name is <UNKNOWN> like my grandfather and his grandfather before him our protagonist introduces himself to us and also introduces the story that stretches back through generations it produces stories within stories stories that evoke the <UNKNOWN> wonder of scotland its rugged mountains <UNKNOWN> in <UNKNOWN> the stuff of legend yet <UNKNOWN> is <UNKNOWN> in reality this is what gives it its special charm it has a rough beauty and authenticity <UNKNOWN> with some of the finest <UNKNOWN> singing you will ever hear br br <UNKNOWN> <UNKNOWN> visits his grandfather in hospital shortly before his death he burns with frustration part of him <UNKNOWN> to be in the twenty first century to hang out in <UNKNOWN> but he is raised on the western <UNKNOWN> among a <UNKNOWN> speaking community br br yet there is a deeper conflict within him he <UNKNOWN> to know the truth the truth behind his <UNKNOWN> ancient stories where does fiction end and he wants to know the truth behind the death of his parents br br he is pulled to make a last <UNKNOWN> journey to the <UNKNOWN> of one of <UNKNOWN> most <UNKNOWN> mountains can the truth be told or is it all in stories br br in this story about stories we <UNKNOWN> bloody battles <UNKNOWN> lovers the <UNKNOWN> of old and the sometimes more <UNKNOWN> <UNKNOWN> of accepted truth in doing so we each connect with <UNKNOWN> as he lives the story of his own life br br <UNKNOWN> the <UNKNOWN> <UNKNOWN> is probably the most honest <UNKNOWN> and genuinely beautiful film of scotland ever made like <UNKNOWN> i got slightly annoyed with the <UNKNOWN> of hanging stories on more stories but also like <UNKNOWN> i <UNKNOWN> this once i saw the <UNKNOWN> picture ' forget the box office <UNKNOWN> of braveheart and its like you might even <UNKNOWN> the <UNKNOWN> famous <UNKNOWN> of the wicker man to see a film that is true to scotland this one is probably unique if you maybe <UNKNOWN> on it deeply enough you might even re <UNKNOWN> the power of storytelling and the age old question of whether there are some truths that cannot be told but only experienced\n",
            "Label: 1\n",
            "__________\n",
            "Review: <START> worst mistake of my life br br i picked this movie up at target for 5 because i figured hey it's sandler i can get some cheap laughs i was wrong completely wrong mid way through the film all three of my friends were asleep and i was still suffering worst plot worst script worst movie i have ever seen i wanted to hit my head up against a wall for an hour then i'd stop and you know why because it felt damn good upon bashing my head in i stuck that damn movie in the <UNKNOWN> and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\n",
            "Label: 0\n",
            "__________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjQTh4d2jsEn"
      },
      "source": [
        "### Padding Sequence on the sentence\n",
        "\n",
        "Making all sentences of equal length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anqTikrCWelo"
      },
      "source": [
        "train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                           value=vocabulary[\"<PAD>\"],\n",
        "                                                           padding='post',\n",
        "                                                           maxlen=256)\n",
        "\n",
        "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                          value=vocabulary[\"<PAD>\"],\n",
        "                                                          padding='post',\n",
        "                                                          maxlen=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmxQ1q6dm-T7"
      },
      "source": [
        "### Analysis on the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngY_XnIokaI2",
        "outputId": "0eaad0d4-52e9-43d9-c3da-0c1eaff3833d"
      },
      "source": [
        "print('Shape of training data:', train_data.shape)\n",
        "print('Shape of testing data:', test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data: (25000, 256)\n",
            "Shape of testing data: (25000, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OyIdPP3kuiI",
        "outputId": "3b449b57-19c6-46c0-ae8f-44cf3f4815dc"
      },
      "source": [
        "print('Shape of training label:', train_label.shape)\n",
        "print('Shape of testing label:', test_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training label: (25000,)\n",
            "Shape of testing label: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCsXNA7yk7sC",
        "outputId": "104c8ee5-a6fd-4105-a74d-9718c11b6de8"
      },
      "source": [
        "print('Feature:', train_data[55])\n",
        "print('Original Sentence:', decode_review(train_data[55]))\n",
        "print('Label:', train_label[55])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature: [2467   17    6  959    4   65    9    6  947   14   20 1481 3827   19\n",
            "  559    5   12  434  152 4392   19 2448 4719   10   10   13   92 6110\n",
            "   15    6  171  388    7 1092    2    5  831 9332   26 8813  469   14\n",
            "  196  196   22   21  148    2    2    2  541  110 3727   11  117    2\n",
            " 5567   26 1755    5 1322    5  718    2 3149 4349  411 4922  146  344\n",
            "    5    2 1806 1533    2    4 1327  905 1074    5    2   94 1321 1708\n",
            "   13  124   13 1829   11    4  750    5  557    4  311  462   11  700\n",
            " 2143    2 1264   75   92   28    8  193   14  538  615  417 5011    9\n",
            "  340   33 2019   42  334 1254 3071  315  148  139   11   63 4922 5933\n",
            "  187    4 1896 1455  137   41  658  497    8    2   68  492    6    2\n",
            "  368    7    2 5540   32 1266   50  351   11   68 1073 6088    2  150\n",
            "   13   66  244 1595   10   10  348  718    2 3499  120    4  153   31\n",
            "   70   64 2237   15   29  520   43    4  432    7    2 2660    2    2\n",
            " 1385    2  239   15    4  167  473    4  239    7 4708 6062   17    6\n",
            "  432    7  668  310    7 1561    2   11    4 1213    5  443 5145    9\n",
            "  118 2116  120   11 3542   10   10   14   20  331  152 3115   24   17\n",
            "   35 1253   24   23   94  205 1303   12  242 5068    6  342   46    7\n",
            "  158   21  146  743   12    6  300   88   12   47   77   38    2  120\n",
            " 1150   11   14 9731]\n",
            "Original Sentence: supernatural as a result the story is a mess this movie hasn't improved with age and it certainly doesn't improve with repeated viewings br br i don't deny that a few moments of fear <UNKNOWN> and general creepiness are scattered throughout this long long film but those <UNKNOWN> <UNKNOWN> <UNKNOWN> blood seen repeatedly in little <UNKNOWN> visions are absurd and laughable and jack <UNKNOWN> infamous tag lines wendy i'm home and <UNKNOWN> johnny merely <UNKNOWN> the movie's dramatic tension and <UNKNOWN> its narrative energy i know i sat in the theater and heard the audience laugh in comic relief <UNKNOWN> glad we don't have to take this stuff seriously finally kubrick is completely at sea or else utterly cynical during those scenes in which wendy wanders around the empty hotel while her husband tries to <UNKNOWN> their son a <UNKNOWN> full of <UNKNOWN> guests all sitting there dead in their party hats <UNKNOWN> now i really am afraid br br given jack <UNKNOWN> brilliance over the years one can only assume that he gave just the sort of <UNKNOWN> rolling <UNKNOWN> <UNKNOWN> scenery <UNKNOWN> performance that the director wanted the performance of shelley duvall as a sort of female version of don <UNKNOWN> in the ghost and mr chicken is best passed over in silence br br this movie simply doesn't succeed not as an adaptation not on its own terms it probably merits a 3 out of 10 but i'm giving it a 1 because it has been so <UNKNOWN> over rated in this forum\n",
            "Label: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsId0qtEsR3m"
      },
      "source": [
        "## Design, train and tune model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obgFD21NsvPK"
      },
      "source": [
        "### Apporach 1: Using Vanilla LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_Z8DeOZl7dm",
        "outputId": "e961538e-829d-434d-bee2-19f4b0cb302e"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(10000, 32, input_length=256))\n",
        "model.add(tf.keras.layers.LSTM(100))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 256, 32)           320000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 373,301\n",
            "Trainable params: 373,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbzwZJE3stcj"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OkxcRzps0ZM",
        "outputId": "d41a1ee7-96ae-4a6b-f55d-5f57754e8872"
      },
      "source": [
        "model.fit(train_data, train_label, validation_data=(test_data, test_label), epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 149s 375ms/step - loss: 0.6915 - accuracy: 0.5386 - val_loss: 0.6709 - val_accuracy: 0.5521\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 146s 374ms/step - loss: 0.6473 - accuracy: 0.6030 - val_loss: 0.6647 - val_accuracy: 0.5526\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 146s 373ms/step - loss: 0.6343 - accuracy: 0.5919 - val_loss: 0.6314 - val_accuracy: 0.5980\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 146s 374ms/step - loss: 0.6118 - accuracy: 0.6300 - val_loss: 0.6678 - val_accuracy: 0.5799\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 146s 374ms/step - loss: 0.6038 - accuracy: 0.6500 - val_loss: 0.6634 - val_accuracy: 0.5570\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 146s 374ms/step - loss: 0.6037 - accuracy: 0.6438 - val_loss: 0.6448 - val_accuracy: 0.5934\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 146s 373ms/step - loss: 0.5243 - accuracy: 0.7489 - val_loss: 0.7081 - val_accuracy: 0.6151\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 146s 373ms/step - loss: 0.4757 - accuracy: 0.7813 - val_loss: 0.5297 - val_accuracy: 0.7622\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 145s 372ms/step - loss: 0.4577 - accuracy: 0.7939 - val_loss: 0.6510 - val_accuracy: 0.6524\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 146s 373ms/step - loss: 0.5084 - accuracy: 0.7336 - val_loss: 0.5316 - val_accuracy: 0.7840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f488d66b450>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u06UzeEgiTaE"
      },
      "source": [
        "### Apporach 2: Using Stacked LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWoxnCvps-CM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0645e8f6-5760-4518-ab13-81f3d4694d5f"
      },
      "source": [
        "stacked_model = tf.keras.models.Sequential()\n",
        "stacked_model.add(tf.keras.layers.Embedding(10000, 32, input_length=256))\n",
        "stacked_model.add(tf.keras.layers.LSTM(100, return_sequences=True))\n",
        "stacked_model.add(tf.keras.layers.LSTM(100))\n",
        "stacked_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "print(stacked_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 256, 32)           320000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256, 100)          53200     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 453,701\n",
            "Trainable params: 453,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0sD6wrKjS1O"
      },
      "source": [
        "stacked_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GorZ3KdnjVow",
        "outputId": "6872f5e2-35ad-4cf2-c08c-af20e2841de6"
      },
      "source": [
        "stacked_model.fit(train_data, train_label, validation_data=(test_data, test_label), epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 302s 765ms/step - loss: 0.6933 - accuracy: 0.5426 - val_loss: 0.6903 - val_accuracy: 0.5193\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 299s 764ms/step - loss: 0.6397 - accuracy: 0.6281 - val_loss: 0.6670 - val_accuracy: 0.5653\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 298s 763ms/step - loss: 0.5727 - accuracy: 0.6931 - val_loss: 0.5645 - val_accuracy: 0.7330\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 298s 762ms/step - loss: 0.4655 - accuracy: 0.7843 - val_loss: 0.5056 - val_accuracy: 0.7542\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 298s 762ms/step - loss: 0.4285 - accuracy: 0.8162 - val_loss: 0.4538 - val_accuracy: 0.8111\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 298s 762ms/step - loss: 0.3880 - accuracy: 0.8293 - val_loss: 0.4273 - val_accuracy: 0.8146\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 298s 762ms/step - loss: 0.3634 - accuracy: 0.8503 - val_loss: 0.4148 - val_accuracy: 0.8169\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 297s 760ms/step - loss: 0.5946 - accuracy: 0.6653 - val_loss: 0.6590 - val_accuracy: 0.5718\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 297s 759ms/step - loss: 0.5688 - accuracy: 0.6866 - val_loss: 0.4162 - val_accuracy: 0.8285\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 298s 762ms/step - loss: 0.3716 - accuracy: 0.8514 - val_loss: 0.4186 - val_accuracy: 0.8134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f488d482dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDLSpDaJuGIa"
      },
      "source": [
        "### Apporach 3: Using Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6YuOn0wjXWp",
        "outputId": "5fb5c7f1-2169-496b-fbc4-907b467196fc"
      },
      "source": [
        "bidirectional_model = tf.keras.models.Sequential()\n",
        "bidirectional_model.add(tf.keras.layers.Embedding(10000, 32, input_length=256))\n",
        "bidirectional_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)))\n",
        "bidirectional_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "print(bidirectional_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 256, 32)           320000    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               106400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 426,601\n",
            "Trainable params: 426,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oecfal35kkhY"
      },
      "source": [
        "bidirectional_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYapE4x4vUlO",
        "outputId": "ec216073-31d4-49c2-eee1-6eb1e07779ad"
      },
      "source": [
        "bidirectional_model.fit(train_data, train_label, validation_data=(test_data, test_label), epochs=10, batch_size=64)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 231s 584ms/step - loss: 0.6918 - accuracy: 0.5549 - val_loss: 0.6736 - val_accuracy: 0.6233\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 228s 582ms/step - loss: 0.4901 - accuracy: 0.7714 - val_loss: 0.3916 - val_accuracy: 0.8356\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 228s 584ms/step - loss: 0.2923 - accuracy: 0.8857 - val_loss: 0.3636 - val_accuracy: 0.8451\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 229s 586ms/step - loss: 0.2190 - accuracy: 0.9175 - val_loss: 0.3542 - val_accuracy: 0.8638\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 228s 584ms/step - loss: 0.1653 - accuracy: 0.9425 - val_loss: 0.3836 - val_accuracy: 0.8648\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 227s 580ms/step - loss: 0.1245 - accuracy: 0.9586 - val_loss: 0.4479 - val_accuracy: 0.8536\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 227s 580ms/step - loss: 0.1043 - accuracy: 0.9659 - val_loss: 0.4636 - val_accuracy: 0.8539\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 226s 578ms/step - loss: 0.0874 - accuracy: 0.9723 - val_loss: 0.5395 - val_accuracy: 0.8376\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 225s 577ms/step - loss: 0.0573 - accuracy: 0.9830 - val_loss: 0.5466 - val_accuracy: 0.8519\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 225s 576ms/step - loss: 0.0649 - accuracy: 0.9788 - val_loss: 0.5991 - val_accuracy: 0.8516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48844e1810>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSH5tA0kV5Zc"
      },
      "source": [
        "#### Conclusion:\n",
        "Among the 3 approaches, we can clearly see that Bidirectional LSTM is working best. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hheQSOJvovc"
      },
      "source": [
        "predictions = bidirectional_model.predict(test_data)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv_kjrLdWY4o"
      },
      "source": [
        "pred_round = np.round(predictions)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5tQ1VXIWdDQ"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_wDY4LOkWgmq",
        "outputId": "a5e60b9d-1194-4a4c-b659-39b83dbd677d"
      },
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(confusion_matrix(test_label, pred_round), annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cz-3l0Dh8Ar"
      },
      "source": [
        "#### Observations:\n",
        "1. Most of the predictions are correct and model is performing almost similar for both the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJu5aZH4iDzZ"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwpWK1WAS-cf"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kevkWUowTucu",
        "outputId": "756e5016-09d3-41fb-8d88-5cf183d56eec"
      },
      "source": [
        "rnd = np.random.randint(0, 100, size=10)\n",
        "for i in rnd:\n",
        "    print('Review:', decode_review(train_data[i]))\n",
        "    print('Label:', train_label[i])\n",
        "    print('Predicted:', int(np.round(predictions[i])))\n",
        "    print('_' * 100)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: <START> really truly <UNKNOWN> <UNKNOWN> awful but actor <UNKNOWN> moore the movie lone ranger <UNKNOWN> himself competently as an actor he's the only one br br a rare treat for five minutes if you want to <UNKNOWN> the depths of <UNKNOWN> transparent special effects southern california as the moon again and again and again and acting so <UNKNOWN> inept that it may be a spoof except that it's clear that it isn't no humor here except unintentionally br br the dialogue may be worse than any of these other aspects and the costumes well enough said plot what plot bad guy well head bad guy and his henchmen including his <UNKNOWN> agent called <UNKNOWN> listen carefully or you'll suspect it's a spoof on the name of <UNKNOWN> <UNKNOWN> ray <UNKNOWN> and his unbelievably inept <UNKNOWN> who however have <UNKNOWN> that never need <UNKNOWN> as does <UNKNOWN> cody so there are numerous <UNKNOWN> <UNKNOWN> br br enjoy <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Label: 0\n",
            "Predicted: 1\n",
            "____________________________________________________________________________________________________\n",
            "Review: <START> i wasn't expecting much and to be honest i didn't like this film the first time around but watching it again and i realised that it's kinda cool sure it's a one joke film but it's a funny gag br br someone posted that it could be better written and it could be i think this film had the potential to be a over the top my cousin <UNKNOWN> but with a horror host instead of a lawyer sadly it's a wasted opportunity with just a bit more writing it could be a classic the kids are underused there's no reason why they should <UNKNOWN> on to elvira apart from the obvious reasons it would have been great to see their relationship <UNKNOWN> i know it's a comedy but it's little differences that separate the good films from the brilliant br br elvira herself is always fun and engaging not to mention <UNKNOWN> every time she smiles you will too it's hard to knock a film when the main character is so charming and it really is her charm don't let her looks fool you into thinking that she's some sort of <UNKNOWN> well she is but she's a nice one the sort of person you'd let look after your kids wouldn't let her cook for them though br br i'd recommend giving it a go br br just don't expect too much br br she's more than just a great set of boobs she's also an incredible pair of legs <PAD> <PAD> <PAD> <PAD>\n",
            "Label: 1\n",
            "Predicted: 1\n",
            "____________________________________________________________________________________________________\n",
            "Review: how often do you knock on a <UNKNOWN> door and when they don't immediately answer you open the door walk in shout a few <UNKNOWN> and then start going through their stuff br br if you were being pursued by someone you just discovered was a murderer what would you do quietly sneak off and hide under a wooden platform or among metal <UNKNOWN> run quietly of course to a <UNKNOWN> old <UNKNOWN> or other <UNKNOWN> structure br br i could be talking about almost any thriller that's come out in the last few years but since this is the the return page obviously i'm talking about the return i saw it free because i work at a movie theater and make a point of screening all the scary movies i thought this one was tolerable aside from the well worn clichs sarah michelle <UNKNOWN> is really drab and looks kind of huh through most of the film the details of the plot are slowly given out as the movie progresses and it's almost enough to make it interesting except there wasn't enough explanation as it moved on and so i was almost lost until the last 2 3 of it br br if you're a die hard thriller fan it's worth seeing at least once if there's nothing better at the theater and you really want to watch a movie eh i guess it's worth a <UNKNOWN> ticket if you thought the trailer made it look like an interesting movie and you can't wait wait\n",
            "Label: 0\n",
            "Predicted: 1\n",
            "____________________________________________________________________________________________________\n",
            "Review: twenty first century to hang out in <UNKNOWN> but he is raised on the western <UNKNOWN> among a <UNKNOWN> speaking community br br yet there is a deeper conflict within him he <UNKNOWN> to know the truth the truth behind his <UNKNOWN> ancient stories where does fiction end and he wants to know the truth behind the death of his parents br br he is pulled to make a last <UNKNOWN> journey to the <UNKNOWN> of one of <UNKNOWN> most <UNKNOWN> mountains can the truth be told or is it all in stories br br in this story about stories we <UNKNOWN> bloody battles <UNKNOWN> lovers the <UNKNOWN> of old and the sometimes more <UNKNOWN> <UNKNOWN> of accepted truth in doing so we each connect with <UNKNOWN> as he lives the story of his own life br br <UNKNOWN> the <UNKNOWN> <UNKNOWN> is probably the most honest <UNKNOWN> and genuinely beautiful film of scotland ever made like <UNKNOWN> i got slightly annoyed with the <UNKNOWN> of hanging stories on more stories but also like <UNKNOWN> i <UNKNOWN> this once i saw the <UNKNOWN> picture ' forget the box office <UNKNOWN> of braveheart and its like you might even <UNKNOWN> the <UNKNOWN> famous <UNKNOWN> of the wicker man to see a film that is true to scotland this one is probably unique if you maybe <UNKNOWN> on it deeply enough you might even re <UNKNOWN> the power of storytelling and the age old question of whether there are some truths that cannot be told but only experienced\n",
            "Label: 1\n",
            "Predicted: 1\n",
            "____________________________________________________________________________________________________\n",
            "Review: supernatural as a result the story is a mess this movie hasn't improved with age and it certainly doesn't improve with repeated viewings br br i don't deny that a few moments of fear <UNKNOWN> and general creepiness are scattered throughout this long long film but those <UNKNOWN> <UNKNOWN> <UNKNOWN> blood seen repeatedly in little <UNKNOWN> visions are absurd and laughable and jack <UNKNOWN> infamous tag lines wendy i'm home and <UNKNOWN> johnny merely <UNKNOWN> the movie's dramatic tension and <UNKNOWN> its narrative energy i know i sat in the theater and heard the audience laugh in comic relief <UNKNOWN> glad we don't have to take this stuff seriously finally kubrick is completely at sea or else utterly cynical during those scenes in which wendy wanders around the empty hotel while her husband tries to <UNKNOWN> their son a <UNKNOWN> full of <UNKNOWN> guests all sitting there dead in their party hats <UNKNOWN> now i really am afraid br br given jack <UNKNOWN> brilliance over the years one can only assume that he gave just the sort of <UNKNOWN> rolling <UNKNOWN> <UNKNOWN> scenery <UNKNOWN> performance that the director wanted the performance of shelley duvall as a sort of female version of don <UNKNOWN> in the ghost and mr chicken is best passed over in silence br br this movie simply doesn't succeed not as an adaptation not on its own terms it probably merits a 3 out of 10 but i'm giving it a 1 because it has been so <UNKNOWN> over rated in this forum\n",
            "Label: 0\n",
            "Predicted: 0\n",
            "____________________________________________________________________________________________________\n",
            "Review: <START> i am rarely moved to make these kind of comments but after sitting through most of <UNKNOWN> dreadful movie i feel like i have really earned the right to say what i feel about it i couldn't actually make it right to the end and became one of the half dozen or more walk outs about 1 3rd of the audience after the <UNKNOWN> plot <UNKNOWN> dialogue and insulting characterisation became just too much to bear this film is all pose and no art all style and no substance it is <UNKNOWN> down by dreadful acting a genuinely dire script indifferent cinematography and student level production values how it got <UNKNOWN> started and finished is a mystery to me i bet you a million <UNKNOWN> it never goes on general release the proper critics would tear it apart a really bad film shockingly bad a really really really poor effort and that is without even mentioning the gratuitous new born <UNKNOWN> gets dropped into a deep fat <UNKNOWN> moment totally meaningless utterly lightweight poorly put together this movie is a dreadful embarrassment for uk cinema <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Label: 0\n",
            "Predicted: 0\n",
            "____________________________________________________________________________________________________\n",
            "Review: should be given to the one who deserves credit and tashan loses in this way and unexpectedly failed to become a hit br br <UNKNOWN> has nothing new to show off his comedian talent here but still reminds of his previous movies he seriously need to form a new image to his fans that would impress them again and again in between saif did a great job in race and now he returned again in his hilarious nature through this movie but he has fully developed himself in the acting field and last but not the least about kareena she looks really hot with bikini dress of which some complain as she became too lean but i myself don't think so instead she became slim yes slim it is a good factor for a female to attract the major people or say male beside them it is nice that <UNKNOWN> son <UNKNOWN> appears in the beginning last as young saif i hope now he too will lean forward in target of making acting as his career br br those who like this tashan they are either mentally <UNKNOWN> or still want to go back to childhood or say want to be admitted in an asylum thumbs down to <UNKNOWN> director <UNKNOWN> <UNKNOWN> <UNKNOWN> who <UNKNOWN> the project offered by <UNKNOWN> raj films in future he should experiment and study the script minimum of 5 years before going into practical directions br br sorry i don't like to rate good stars to this type of junk movies\n",
            "Label: 0\n",
            "Predicted: 1\n",
            "____________________________________________________________________________________________________\n",
            "Review: <START> i really must have caught a different film from the rest of the <UNKNOWN> on this site because at a screening of the film last night the audience was so <UNKNOWN> by the <UNKNOWN> that i'm not even kidding half walked out shot as if the filmmaker thought he were approaching some daring new territory by presenting a homosexual coming of age story the film <UNKNOWN> david lynch inspired visuals with fassbinder inspired acting the performances in this film are so dull and bored that i figured one of the actors was going to pass out by how uninspired they seemed to be by the script what's worse is that it's colored like an episode of miami vice i don't know who this director thinks he is maybe he has <UNKNOWN> of the surreal like <UNKNOWN> <UNKNOWN> etc but the problem is that all of the <UNKNOWN> mentioned directors display a level of <UNKNOWN> sensibility that is sorely lacking here i could understand the <UNKNOWN> of this film about ten years ago but when we've got masterpieces such as bad <UNKNOWN> mysterious skin and show me love why bother with this cinematic turd there is nothing new to be seen here <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Label: 0\n",
            "Predicted: 0\n",
            "____________________________________________________________________________________________________\n",
            "Review: <START> this movie is wonderful br br i was <UNKNOWN> i should say and surprised because of how uniquely it was done the cast the <UNKNOWN> the effects everything magnificent i mean it was a love story yes but what made it outstanding from the rest was that it was told in an entertaining wholesome manner br br for me it is the representation of modern fairy tale it's like the modern peter pan simply amazing br br i surely would buy a copy of this the moment it hit the market br br this movie is really a double must see one 10 stars for that <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Label: 1\n",
            "Predicted: 0\n",
            "____________________________________________________________________________________________________\n",
            "Review: <START> i am rarely moved to make these kind of comments but after sitting through most of <UNKNOWN> dreadful movie i feel like i have really earned the right to say what i feel about it i couldn't actually make it right to the end and became one of the half dozen or more walk outs about 1 3rd of the audience after the <UNKNOWN> plot <UNKNOWN> dialogue and insulting characterisation became just too much to bear this film is all pose and no art all style and no substance it is <UNKNOWN> down by dreadful acting a genuinely dire script indifferent cinematography and student level production values how it got <UNKNOWN> started and finished is a mystery to me i bet you a million <UNKNOWN> it never goes on general release the proper critics would tear it apart a really bad film shockingly bad a really really really poor effort and that is without even mentioning the gratuitous new born <UNKNOWN> gets dropped into a deep fat <UNKNOWN> moment totally meaningless utterly lightweight poorly put together this movie is a dreadful embarrassment for uk cinema <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Label: 0\n",
            "Predicted: 0\n",
            "____________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iww6WmptWF9n"
      },
      "source": [
        "#### Conclusion:\n",
        "As we can see in the above, out of 10, only 4 were incorrect predictions. The model is working good and can be improved by tuning the parameter and we can increase number of features as well to improve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F85qA4LGT1xI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}